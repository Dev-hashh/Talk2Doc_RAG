{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb6e341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dev\\talk2doc\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5776f0",
   "metadata": {},
   "source": [
    "#Loading BDE-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f94788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dev\\talk2doc\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 211.32it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "\n",
    "text = \"Transformers use self-attention mechanisms.\"\n",
    "embedding = model.encode(text, normalize_embeddings=True)\n",
    "\n",
    "print(len(embedding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88227a",
   "metadata": {},
   "source": [
    "#CREATE FAISS INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80fc2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dimension = 384\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product (cosine since normalized)\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Transformers use self-attention.\",\n",
    "    \"India's capital is New Delhi.\"\n",
    "]\n",
    "\n",
    "doc_embeddings = model.encode(\n",
    "    [\"passage: \" + doc for doc in documents],\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "index.add(np.array(doc_embeddings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e3f33",
   "metadata": {},
   "source": [
    "Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8103f559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "India's capital is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of France?\"\n",
    "\n",
    "query_embedding = model.encode(\n",
    "    \"query: \" + query,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "D, I = index.search(np.array([query_embedding]), k=2)\n",
    "for idx in I[0]:\n",
    "    print(documents[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e3bb2",
   "metadata": {},
   "source": [
    "Inject into deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af80ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context retrieved:\n",
      "Sending request...\n",
      "hello\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "context = \"\\n\".join([documents[i] for i in I[0]])\n",
    "\n",
    "print(\"Context retrieved:\")\n",
    "prompt = f\"\"\"\n",
    "Use only the following context to answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "print(\"Sending request...\")\n",
    "response = requests.post(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    json={\n",
    "        \"model\": \"deepseek-v3.1:671b-cloud\",\n",
    "        \n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    ")\n",
    "print(\"hello\")\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "if \"response\" in data:\n",
    "    print(data[\"response\"])\n",
    "else:\n",
    "    print(\"Error:\", data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
